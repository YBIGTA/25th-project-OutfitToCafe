{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnJwtRMLHu3P",
        "outputId": "28762fb1-72f3-4e67-e02e-33a78d0aabc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClHyT0QQNRCe",
        "outputId": "114998c3-bd53-4ad3-cad4-1526ca3b3b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPfdeyAZNWNT"
      },
      "outputs": [],
      "source": [
        "# I want to start importing the base packages that we need to train our CNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZCcZjvOND7X"
      },
      "outputs": [],
      "source": [
        "class PreprocessedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder):\n",
        "        self.file_paths = [os.path.join(dp, f) for dp, dn, filenames in os.walk(folder) for f in filenames]\n",
        "        self.classes = sorted(set(os.path.basename(os.path.dirname(fp)) for fp in self.file_paths))\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.load(self.file_paths[idx])\n",
        "        label = self.get_label_from_path(self.file_paths[idx])\n",
        "        return image, label\n",
        "\n",
        "    def get_label_from_path(self, path):\n",
        "        # Get the class name (folder name) from the path\n",
        "        class_name = os.path.basename(os.path.dirname(path))\n",
        "        # Map the class name to an integer label\n",
        "        return self.class_to_idx[class_name]\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "base_train_dataset = PreprocessedDataset(\"/content/drive/MyDrive/YBIGTA 신입플/TransformedDatasets/base_NB_train\")\n",
        "blur_train_dataset = PreprocessedDataset(\"/content/drive/MyDrive/YBIGTA 신입플/TransformedDatasets/blur_NB_train\")\n",
        "val_dataset = PreprocessedDataset(\"/content/drive/MyDrive/YBIGTA 신입플/TransformedDatasets/NB_val\")\n",
        "test_dataset = PreprocessedDataset(\"/content/drive/MyDrive/YBIGTA 신입플/TransformedDatasets/NB_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIyzDaJwNYjz"
      },
      "outputs": [],
      "source": [
        "base_train_loader = DataLoader(base_train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "blur_train_loader = DataLoader(blur_train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6uwG90sOhFP"
      },
      "outputs": [],
      "source": [
        "base_dataloaders = {'train': base_train_loader, 'val': val_loader, \"test\": test_loader}\n",
        "base_image_datasets = {'train': base_train_dataset, 'val': val_dataset, \"test\": test_dataset}\n",
        "blur_dataloaders = {'train': blur_train_loader, 'val': val_loader, \"test\": test_loader}\n",
        "blur_image_datasets = {'train': blur_train_dataset, 'val': val_dataset, \"test\": test_dataset}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAk-AM2iOyeQ"
      },
      "source": [
        "I loaded my datasets that we will use to train a model with 2 purposes:\n",
        "- Classification\n",
        "- Feature Extraction that can be used to calculate the similarity between the 12 classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from typing import Type, List, Optional\n",
        "from torchsummary import summary\n",
        "from torch.optim import Optimizer\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "D1c86O58BwOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6Gr0LRlPDPf"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(self, in_planes: int, planes: int, stride: int = 1) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # VGG의 철학을 따라 3 x 3 filter 사용\n",
        "        self.conv1: nn.Conv2d = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1: nn.BatchNorm2d = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # 마찬가지로 3 x 3 filter 사용, 2번째 conv layer에서는 차원이 변하지 않음\n",
        "        self.conv2: nn.Conv2d = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2: nn.BatchNorm2d = nn.BatchNorm2d(planes)\n",
        "\n",
        "        ######################## ResNet의 핵심 부분 ######################################\n",
        "        #\n",
        "        # Mapping을 추가해 주어야 하는데, dimension이 변하는 부분을 고려해야 함.\n",
        "        # (ResNet에서는 complexity를 유지하기 위해서 dimension이 변하는 경우에만 stride = 2로 변경)\n",
        "        #\n",
        "        # 1. stride == 1인 경우 : dimension이 변하지 않음 -> identity mapping 사용\n",
        "        # 2. stride != 1인 경우 : dimension이 변하는 경우이므로 identity mapping을 사용할 수 없음\n",
        "        #                        -> 1 x 1 convolution을 활용하여 차원을 맞추어 줌.\n",
        "        #\n",
        "\n",
        "        self.shortcut: nn.Sequential = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # 실제 논문에서 사용한 방식과 거의 유사함 (shortcut 위치 등)\n",
        "        out: torch.Tensor = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1) -> None:\n",
        "        super(BottleNeck, self).__init__()\n",
        "\n",
        "        # First 1x1 convolution and batch no`rm\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 3x3 convolution and batch norm\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Last 1x1 convolution and batch norm\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        # Shortcut connection for residuals\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # First 1x1 conv + batch norm + ReLU\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        # 3x3 conv + batch norm + ReLU\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "\n",
        "        # Last 1x1 conv + batch norm\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        # Add the shortcut (residual) connection\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        # Apply final ReLU activation\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "zz22qnO-OlSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block: Type[nn.Module], num_blocks: List[int], num_classes: int = 12, init_weights: bool = True) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels: int = 64\n",
        "\n",
        "        self.conv1: nn.Sequential = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv2_x: nn.Sequential = self._make_layer(block, 64, num_blocks[0], 1)\n",
        "        self.conv3_x: nn.Sequential = self._make_layer(block, 128, num_blocks[1], 2)\n",
        "        self.conv4_x: nn.Sequential = self._make_layer(block, 256, num_blocks[2], 2)\n",
        "        self.conv5_x: nn.Sequential = self._make_layer(block, 512, num_blocks[3], 2)\n",
        "\n",
        "        self.avg_pool: nn.AdaptiveAvgPool2d = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc: nn.Linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block: Type[nn.Module], out_channels: int, num_blocks: int, stride: int) -> nn.Sequential:\n",
        "        strides: List[int] = [stride] + [1] * (num_blocks - 1)\n",
        "        layers: List[nn.Module] = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        output: torch.Tensor = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.conv5_x(output)\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "G6cM_cHBOnVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18() -> ResNet:\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def resnet34() -> ResNet:\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def resnet50() -> ResNet:\n",
        "    return ResNet(BottleNeck, [3,4,6,3])\n",
        "\n",
        "def resnet101() -> ResNet:\n",
        "    return ResNet(BottleNeck, [3,4,23,3])\n",
        "\n",
        "def resnet152() -> ResNet:\n",
        "    return ResNet(BottleNeck, [3,8,36,3])"
      ],
      "metadata": {
        "id": "x6k22poPOrtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "net = resnet18()\n",
        "model_name = 'resnet18'\n",
        "net = net.to(device)\n",
        "net = torch.nn.DataParallel(net)\n",
        "\n",
        "learning_rate = 0.1\n",
        "file_name = f'{model_name}_fashion.pt'\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)"
      ],
      "metadata": {
        "id": "P9Ad6g2rOv51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch: int) -> None:\n",
        "    print(\"------------------------------------------------------------\")\n",
        "    print('\\nEpoch %d (train)' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(blur_train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        benign_outputs = net(inputs)\n",
        "        loss = criterion(benign_outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = benign_outputs.max(1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('\\nBatch', str(batch_idx))\n",
        "            print('Accuracy (train):', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
        "            print('Loss:', loss.item())\n",
        "\n",
        "    print('\\nTotal accuracy (train):', 100. * correct / total)\n",
        "    print('Total loss:', train_loss)"
      ],
      "metadata": {
        "id": "4-Opwh_JUgE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer: Optimizer, epoch: int) -> None:\n",
        "    lr = learning_rate\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    if epoch >= 150:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "TKiue0mPWSXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(epoch: int) -> float:\n",
        "    print('\\nEpoch: %d (validation)' % epoch)\n",
        "    net.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            total += targets.size(0)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            validation_loss += criterion(outputs, targets).item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
        "\n",
        "    print('\\nAccuracy (validation):', accuracy)\n",
        "    print('Validation average loss:', validation_loss / total)\n",
        "    print('F1 Score (validation):', f1)\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "id": "nRraQyvAYlqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch: int) -> float:\n",
        "    print('\\nEpoch: %d (test)' % epoch)\n",
        "    net.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        total += targets.size(0)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss += criterion(outputs, targets).item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        all_targets.extend(targets.cpu().numpy())\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
        "\n",
        "    print('\\nAccuracy (test):', accuracy)\n",
        "    print('Test average loss:', loss / total)\n",
        "    print('F1 Score (test):', f1)\n",
        "\n",
        "    state = {\n",
        "        'net': net.state_dict()\n",
        "    }\n",
        "    if not os.path.isdir('/content/drive/MyDrive/YBIGTA 신입플/Models'):\n",
        "        os.mkdir('/content/drive/MyDrive/YBIGTA 신입플/Models')\n",
        "    torch.save(state, '/content/drive/MyDrive/YBIGTA 신입플/Models/' + file_name)\n",
        "    print('Model Saved!')\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "id": "IBywmnZ6WT5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = []\n",
        "for epoch in range(0, 10):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(epoch)\n",
        "    f1_val = validate(epoch)\n",
        "    f1_test = test(epoch)\n",
        "    f1_scores.append((f1_val, f1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkXTw3eHWWKt",
        "outputId": "d791d3fd-7526-41c8-f855-082e04e520eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 0 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.15625\n",
            "Loss: 2.6361513137817383\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.15625\n",
            "Loss: 2.5051424503326416\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.03125\n",
            "Loss: 2.521423578262329\n",
            "\n",
            "Total accuracy (train): 11.273809523809524\n",
            "Total loss: 742.7755472660065\n",
            "\n",
            "Epoch: 0 (validation)\n",
            "\n",
            "Accuracy (validation): 16.61111111111111\n",
            "Validation average loss: 0.07520795543988545\n",
            "F1 Score (validation): 0.12008587975536697\n",
            "\n",
            "Epoch: 0 (test)\n",
            "\n",
            "Accuracy (test): 15.88888888888889\n",
            "Test average loss: 0.07537256300449371\n",
            "F1 Score (test): 0.11436145076719909\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 1 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.25\n",
            "Loss: 2.259626626968384\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.3125\n",
            "Loss: 2.1973302364349365\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.09375\n",
            "Loss: 2.4042673110961914\n",
            "\n",
            "Total accuracy (train): 17.738095238095237\n",
            "Total loss: 608.7052080631256\n",
            "\n",
            "Epoch: 1 (validation)\n",
            "\n",
            "Accuracy (validation): 17.61111111111111\n",
            "Validation average loss: 0.07237825493017833\n",
            "F1 Score (validation): 0.09827418930388926\n",
            "\n",
            "Epoch: 1 (test)\n",
            "\n",
            "Accuracy (test): 17.5\n",
            "Test average loss: 0.0731205815076828\n",
            "F1 Score (test): 0.10446928219048673\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 2 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.15625\n",
            "Loss: 2.3462183475494385\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.125\n",
            "Loss: 2.2396013736724854\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.125\n",
            "Loss: 2.177182197570801\n",
            "\n",
            "Total accuracy (train): 20.63095238095238\n",
            "Total loss: 584.8847053050995\n",
            "\n",
            "Epoch: 2 (validation)\n",
            "\n",
            "Accuracy (validation): 18.833333333333332\n",
            "Validation average loss: 0.07169795208507114\n",
            "F1 Score (validation): 0.1532799951582098\n",
            "\n",
            "Epoch: 2 (test)\n",
            "\n",
            "Accuracy (test): 19.444444444444443\n",
            "Test average loss: 0.07168044103516473\n",
            "F1 Score (test): 0.15712968908224353\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 3 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.3125\n",
            "Loss: 2.09334135055542\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.3125\n",
            "Loss: 2.0885653495788574\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.25\n",
            "Loss: 2.2580342292785645\n",
            "\n",
            "Total accuracy (train): 22.80952380952381\n",
            "Total loss: 569.9718888998032\n",
            "\n",
            "Epoch: 3 (validation)\n",
            "\n",
            "Accuracy (validation): 18.27777777777778\n",
            "Validation average loss: 0.07208940078814824\n",
            "F1 Score (validation): 0.11563688755442512\n",
            "\n",
            "Epoch: 3 (test)\n",
            "\n",
            "Accuracy (test): 17.555555555555557\n",
            "Test average loss: 0.07305038733614816\n",
            "F1 Score (test): 0.10813668336230363\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 4 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.25\n",
            "Loss: 2.1038596630096436\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.25\n",
            "Loss: 2.234837532043457\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.21875\n",
            "Loss: 2.0457162857055664\n",
            "\n",
            "Total accuracy (train): 23.964285714285715\n",
            "Total loss: 561.1656826734543\n",
            "\n",
            "Epoch: 4 (validation)\n",
            "\n",
            "Accuracy (validation): 24.0\n",
            "Validation average loss: 0.0670645597908232\n",
            "F1 Score (validation): 0.17545597148961412\n",
            "\n",
            "Epoch: 4 (test)\n",
            "\n",
            "Accuracy (test): 24.27777777777778\n",
            "Test average loss: 0.06842219432195028\n",
            "F1 Score (test): 0.18032244449811044\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 5 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.09375\n",
            "Loss: 2.409468173980713\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.3125\n",
            "Loss: 2.1618101596832275\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.28125\n",
            "Loss: 2.0314998626708984\n",
            "\n",
            "Total accuracy (train): 25.571428571428573\n",
            "Total loss: 546.6251244544983\n",
            "\n",
            "Epoch: 5 (validation)\n",
            "\n",
            "Accuracy (validation): 26.22222222222222\n",
            "Validation average loss: 0.06536458253860473\n",
            "F1 Score (validation): 0.19059965232934692\n",
            "\n",
            "Epoch: 5 (test)\n",
            "\n",
            "Accuracy (test): 25.555555555555557\n",
            "Test average loss: 0.06633441931671566\n",
            "F1 Score (test): 0.18382073370307564\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 6 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.21875\n",
            "Loss: 1.973719835281372\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.25\n",
            "Loss: 2.103135108947754\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.40625\n",
            "Loss: 1.8493878841400146\n",
            "\n",
            "Total accuracy (train): 28.488095238095237\n",
            "Total loss: 532.6001446247101\n",
            "\n",
            "Epoch: 6 (validation)\n",
            "\n",
            "Accuracy (validation): 25.0\n",
            "Validation average loss: 0.0673232501745224\n",
            "F1 Score (validation): 0.2112549911779424\n",
            "\n",
            "Epoch: 6 (test)\n",
            "\n",
            "Accuracy (test): 25.38888888888889\n",
            "Test average loss: 0.06698398139741686\n",
            "F1 Score (test): 0.21580198746896387\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 7 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.15625\n",
            "Loss: 2.1223394870758057\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.34375\n",
            "Loss: 1.8438904285430908\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.28125\n",
            "Loss: 1.9712449312210083\n",
            "\n",
            "Total accuracy (train): 29.571428571428573\n",
            "Total loss: 519.6635267734528\n",
            "\n",
            "Epoch: 7 (validation)\n",
            "\n",
            "Accuracy (validation): 25.22222222222222\n",
            "Validation average loss: 0.06711221873760223\n",
            "F1 Score (validation): 0.2389311548542521\n",
            "\n",
            "Epoch: 7 (test)\n",
            "\n",
            "Accuracy (test): 24.22222222222222\n",
            "Test average loss: 0.06779542545477549\n",
            "F1 Score (test): 0.230601357100284\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 8 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.25\n",
            "Loss: 2.1301233768463135\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.40625\n",
            "Loss: 1.6704998016357422\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.46875\n",
            "Loss: 1.7031522989273071\n",
            "\n",
            "Total accuracy (train): 31.666666666666668\n",
            "Total loss: 509.18142461776733\n",
            "\n",
            "Epoch: 8 (validation)\n",
            "\n",
            "Accuracy (validation): 12.11111111111111\n",
            "Validation average loss: 0.1091405701968405\n",
            "F1 Score (validation): 0.0626728664157922\n",
            "\n",
            "Epoch: 8 (test)\n",
            "\n",
            "Accuracy (test): 12.777777777777779\n",
            "Test average loss: 0.10850810478130976\n",
            "F1 Score (test): 0.06256496533479129\n",
            "Model Saved!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 9 (train)\n",
            "\n",
            "Batch 0\n",
            "Accuracy (train): 0.46875\n",
            "Loss: 1.6777255535125732\n",
            "\n",
            "Batch 100\n",
            "Accuracy (train): 0.28125\n",
            "Loss: 2.011047840118408\n",
            "\n",
            "Batch 200\n",
            "Accuracy (train): 0.25\n",
            "Loss: 1.8559147119522095\n",
            "\n",
            "Total accuracy (train): 32.05952380952381\n",
            "Total loss: 502.7911448478699\n",
            "\n",
            "Epoch: 9 (validation)\n",
            "\n",
            "Accuracy (validation): 27.38888888888889\n",
            "Validation average loss: 0.06375690749949879\n",
            "F1 Score (validation): 0.22373683625115273\n",
            "\n",
            "Epoch: 9 (test)\n",
            "\n",
            "Accuracy (test): 28.166666666666668\n",
            "Test average loss: 0.06340762773321734\n",
            "F1 Score (test): 0.23572037809507898\n",
            "Model Saved!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}