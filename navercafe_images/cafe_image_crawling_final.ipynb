{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# 웹 드라이버 옵션 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 리스트 컨테이너를 찾지 못했습니다 (카페 ID: 1127892000): Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001008b5088 cxxbridge1$str$ptr + 1887276\n",
      "1   chromedriver                        0x00000001008ad764 cxxbridge1$str$ptr + 1856264\n",
      "2   chromedriver                        0x00000001004bc82c cxxbridge1$string$len + 88524\n",
      "3   chromedriver                        0x0000000100500834 cxxbridge1$string$len + 367060\n",
      "4   chromedriver                        0x000000010053848c cxxbridge1$string$len + 595500\n",
      "5   chromedriver                        0x00000001004f5474 cxxbridge1$string$len + 321044\n",
      "6   chromedriver                        0x00000001004f60e4 cxxbridge1$string$len + 324228\n",
      "7   chromedriver                        0x000000010087ca6c cxxbridge1$str$ptr + 1656336\n",
      "8   chromedriver                        0x00000001008814c8 cxxbridge1$str$ptr + 1675372\n",
      "9   chromedriver                        0x0000000100862950 cxxbridge1$str$ptr + 1549556\n",
      "10  chromedriver                        0x0000000100881c78 cxxbridge1$str$ptr + 1677340\n",
      "11  chromedriver                        0x0000000100854660 cxxbridge1$str$ptr + 1491460\n",
      "12  chromedriver                        0x000000010089eac0 cxxbridge1$str$ptr + 1795684\n",
      "13  chromedriver                        0x000000010089ec3c cxxbridge1$str$ptr + 1796064\n",
      "14  chromedriver                        0x00000001008ad398 cxxbridge1$str$ptr + 1855292\n",
      "15  libsystem_pthread.dylib             0x000000019ae7ef94 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000019ae79d34 thread_start + 8\n",
      "\n",
      "Downloaded downloaded_images/cafe_1709396208/image_0.jpg for cafe ID 1709396208\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open('numbered_cafes.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 카페 ID 리스트 추출\n",
    "cafe_ids = [cafe['id값'] for cafe in data]\n",
    "\n",
    "# 웹 드라이버 옵션 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "\n",
    "# 웹 드라이버 초기화\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "for cafe_id in cafe_ids:\n",
    "    try:\n",
    "        # URL 구성\n",
    "        url = f'https://map.naver.com/p/entry/place/{cafe_id}?c=15.00,0,0,0,dh&placePath=/photo'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(30)\n",
    "\n",
    "        # iframe 전환\n",
    "        driver.switch_to.frame('entryIframe')\n",
    "        time.sleep(5)  # iframe이 로드되기를 기다림\n",
    "\n",
    "        # 이미지 리스트 컨테이너 찾기\n",
    "        try:\n",
    "            image_list_container = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, '#app-root > div > div > div > div:nth-child(6) > div.place_section.no_margin > div > div > div > div:nth-child(1)'))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 리스트 컨테이너를 찾지 못했습니다 (카페 ID: {cafe_id}): {e}\")\n",
    "            continue\n",
    "\n",
    "        # 페이지 다운을 통한 추가 이미지 로드 (필요시)\n",
    "        body = driver.find_element(By.TAG_NAME, 'body')\n",
    "        for _ in range(5):  # 최대 5번 페이지 다운\n",
    "            body.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(1)\n",
    "\n",
    "        # 페이지 소스 가져오기\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # 모든 img 태그를 찾아서 src 속성이 있는 것들만 선택\n",
    "        img_tags = soup.select('#app-root div div div div:nth-child(6) div.place_section.no_margin div div div div:nth-child(1) img')\n",
    "\n",
    "        # 이미지 저장 경로 설정\n",
    "        save_dir = os.path.join(\"downloaded_images\", f\"cafe_{cafe_id}\")\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        # 이미지 다운로드 (모든 이미지 다운로드)\n",
    "        for i, img_tag in enumerate(img_tags):\n",
    "            image_url = img_tag.get('src')\n",
    "            if image_url:  # src 속성이 존재할 경우에만 다운로드\n",
    "                file_name = os.path.join(save_dir, f'image_{i}.jpg')\n",
    "                urllib.request.urlretrieve(image_url, file_name)\n",
    "                print(f\"Downloaded {file_name} for cafe ID {cafe_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생 (카페 ID: {cafe_id}): {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.switch_to.default_content()  # 다음 카페 ID로 넘어가기 전에 메인 콘텐츠로 돌아가기\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()\n",
    "\n",
    "print(\"모든 카페의 이미지 크롤링 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오류 발생: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=127.0.6533.101)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000105205088 cxxbridge1$str$ptr + 1887276\n",
      "1   chromedriver                        0x00000001051fd764 cxxbridge1$str$ptr + 1856264\n",
      "2   chromedriver                        0x0000000104e0c82c cxxbridge1$string$len + 88524\n",
      "3   chromedriver                        0x0000000104de7e50 core::str::slice_error_fail::he7b2aa4898bc357e + 3908\n",
      "4   chromedriver                        0x0000000104e75574 cxxbridge1$string$len + 517908\n",
      "5   chromedriver                        0x0000000104e87dd8 cxxbridge1$string$len + 593784\n",
      "6   chromedriver                        0x0000000104e45474 cxxbridge1$string$len + 321044\n",
      "7   chromedriver                        0x0000000104e460e4 cxxbridge1$string$len + 324228\n",
      "8   chromedriver                        0x00000001051cca6c cxxbridge1$str$ptr + 1656336\n",
      "9   chromedriver                        0x00000001051d14c8 cxxbridge1$str$ptr + 1675372\n",
      "10  chromedriver                        0x00000001051b2950 cxxbridge1$str$ptr + 1549556\n",
      "11  chromedriver                        0x00000001051d1c78 cxxbridge1$str$ptr + 1677340\n",
      "12  chromedriver                        0x00000001051a4660 cxxbridge1$str$ptr + 1491460\n",
      "13  chromedriver                        0x00000001051eeac0 cxxbridge1$str$ptr + 1795684\n",
      "14  chromedriver                        0x00000001051eec3c cxxbridge1$str$ptr + 1796064\n",
      "15  chromedriver                        0x00000001051fd398 cxxbridge1$str$ptr + 1855292\n",
      "16  libsystem_pthread.dylib             0x000000019dae6f94 _pthread_start + 136\n",
      "17  libsystem_pthread.dylib             0x000000019dae1d34 thread_start + 8\n",
      "\n",
      "이미지 크롤링 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# URL 구성\n",
    "url = 'https://map.naver.com/p/entry/place/1536816099?c=15.00,0,0,0,dh&placePath=/photo'\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "try:\n",
    "    # iframe 전환\n",
    "    driver.switch_to.frame('entryIframe')\n",
    "    time.sleep(5)  # iframe이 로드되기를 기다림\n",
    "\n",
    "    # 이미지 리스트 컨테이너 찾기\n",
    "    image_list_container = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, '#app-root > div > div > div > div:nth-child(6) > div.place_section.no_margin > div > div > div > div:nth-child(1)'))\n",
    "    )\n",
    "\n",
    "    # 페이지 다운을 통한 추가 이미지 로드 (필요시)\n",
    "    body = driver.find_element(By.TAG_NAME, 'body')\n",
    "    for _ in range(5):  # 최대 5번 페이지 다운\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # 페이지 소스 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 모든 img 태그를 찾아서 src 속성이 있는 것들만 선택\n",
    "    img_tags = soup.select('#app-root div div div div:nth-child(6) div.place_section.no_margin div div div div:nth-child(1) img')\n",
    "\n",
    "    # 이미지 저장 경로 설정\n",
    "    save_dir = \"downloaded_images\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # 이미지 다운로드 (모든 이미지 다운로드)\n",
    "    for i, img_tag in enumerate(img_tags):\n",
    "        image_url = img_tag.get('src')\n",
    "        if image_url:  # src 속성이 존재할 경우에만 다운로드\n",
    "            file_name = os.path.join(save_dir, f'image_{i}.jpg')\n",
    "            try:\n",
    "                urllib.request.urlretrieve(image_url, file_name)\n",
    "                print(f\"Downloaded {file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {image_url}: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n",
    "finally:\n",
    "    # 브라우저 종료\n",
    "    driver.quit()\n",
    "\n",
    "print(\"이미지 크롤링 및 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색을 통한 이미지 추출.\n",
    "\n",
    "https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&ssc=tab.nx.all&query=모센즈스위트+성수&oquery=베러초이스+성수&tqi=ir2b4sqo1Lwssfn2eLZssssss6K-223192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "IMAGE = input(\"검색할 이미지를 입력하세요: \")\n",
    "CNT = int(input(\"저장할 이미지 개수를 입력하세요: \"))\n",
    "### Chrome web 사용.\n",
    "options = webdriver.ChromeOptions()                     # Chrome 창의 옵션을 설정할 수 있는 코드.\n",
    "options.add_argument('--no-sandbox')                    \n",
    "options.add_argument('--disable-dev-shm-usage')         \n",
    "options.add_argument('--headless')                      # headless : Broswer 창을 띄우지 않고 수행 (colab에서는 필수).\n",
    "# options.add_argument(\"window-size = 1920,1080\")       # window size 설정\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome(options = options)           # 위 Option을 적용한 Chrome 창을 실행.\n",
    "browser.maximize_window()                               # browser 창 최대화\n",
    "\n",
    "### 이미지를 검색할 페이지 이동\n",
    "url = \"https://www.naver.com\"\n",
    "browser.get(url)\n",
    "\n",
    "### 이미지 검색\n",
    "elem = browser.find_element(By.NAME, \"query\")\n",
    "elem.send_keys(IMAGE)\n",
    "elem.send_keys(Keys.ENTER)\n",
    "time.sleep(3)   # 검색 완료까지 대기. \n",
    "\n",
    "### 이미지 탭 클릭\n",
    "elem = browser.find_element(By.XPATH, '//*[@id=\"lnb\"]/div[1]/div/div[1]/div/div[1]/div[3]/a' )\n",
    "elem.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling images for: 오푸 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230418_206%2F1681744751969cj4AO_PNG%2F%25BD%25BA%25C5%25A9%25B8%25B0%25BC%25A6_2023-04-18_%25BF%25C0%25C0%25FC_12.17.59.png\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231208_266%2F1702014763303lqL8W_JPEG%2F%25C5%25AB%25C4%25A7%25B4%25EB%25B9%25DD.jpg\n",
      "Crawling images for: 모센즈스위트 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221117_90%2F1668645854289hCaW0_JPEG%2FKakaoTalk_Photo_2022-11-17-09-43-51_004.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230614_131%2F1686730256947WWo2u_JPEG%2FIMG_1474.JPG\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "# 네이버 모바일 검색 URL 패턴\n",
    "search_url = \"https://m.search.naver.com/search.naver?sm=mtp_hty.top&where=m&query={}\"\n",
    "\n",
    "# 카페 목록 (JSON 파일로부터 읽은 데이터)\n",
    "cafes = [\n",
    "    {\"번호\": 1, \"카페명\": \"오푸 성수\"},\n",
    "    {\"번호\": 2, \"카페명\": \"모센즈스위트 성수\"},\n",
    "    # 나머지 카페들...\n",
    "]\n",
    "\n",
    "def crawl_images(cafe_name):\n",
    "    # 카페명을 URL에 맞게 인코딩\n",
    "    encoded_cafe_name = urllib.parse.quote(cafe_name)\n",
    "    url = search_url.format(encoded_cafe_name)\n",
    "\n",
    "    # 네이버 검색 결과 페이지 요청\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve search results for {cafe_name}\")\n",
    "        return []\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 첫 번째 selector로 이미지 태그를 선택하여 src 속성 추출\n",
    "    image_tags_1 = soup.select('img.K0PDV._div')\n",
    "    image_urls_1 = [img['src'] for img in image_tags_1 if 'src' in img.attrs]\n",
    "\n",
    "    # 첫 번째 리스트의 마지막 이미지를 제외\n",
    "    if image_urls_1:\n",
    "        image_urls_1 = image_urls_1[:-1]\n",
    "\n",
    "    # 두 번째 selector로 음식 사진 이미지 태그를 선택하여 src 속성 추출\n",
    "    image_tags_2 = soup.select('#place-main-section-root > div > div:nth-child(4) > div.place_section_content > ul > li > a > div.ZHqBk > div > div.lazyload-wrapper img.K0PDV')\n",
    "    image_urls_2 = [img['src'] for img in image_tags_2 if 'src' in img.attrs]\n",
    "\n",
    "    # 두 리스트를 합쳐서 반환\n",
    "    all_image_urls = image_urls_1 + image_urls_2\n",
    "    return all_image_urls\n",
    "\n",
    "# 각 카페별로 이미지 크롤링 수행\n",
    "for cafe in cafes:\n",
    "    cafe_name = cafe[\"카페명\"]\n",
    "    print(f\"Crawling images for: {cafe_name}\")\n",
    "    image_urls = crawl_images(cafe_name)\n",
    "    for idx, url in enumerate(image_urls):\n",
    "        print(f\"Image {idx + 1}: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling images for: 오푸 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230418_206%2F1681744751969cj4AO_PNG%2F%25BD%25BA%25C5%25A9%25B8%25B0%25BC%25A6_2023-04-18_%25BF%25C0%25C0%25FC_12.17.59.png\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231208_266%2F1702014763303lqL8W_JPEG%2F%25C5%25AB%25C4%25A7%25B4%25EB%25B9%25DD.jpg\n",
      "Crawling images for: 모센즈스위트 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221117_90%2F1668645854289hCaW0_JPEG%2FKakaoTalk_Photo_2022-11-17-09-43-51_004.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230614_131%2F1686730256947WWo2u_JPEG%2FIMG_1474.JPG\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "# 네이버 모바일 검색 URL 패턴\n",
    "search_url = \"https://m.search.naver.com/search.naver?sm=mtp_hty.top&where=m&query={}\"\n",
    "\n",
    "# 카페 목록 (JSON 파일로부터 읽은 데이터)\n",
    "cafes = [\n",
    "    {\"번호\": 1, \"카페명\": \"오푸 성수\"},\n",
    "    {\"번호\": 2, \"카페명\": \"모센즈스위트 성수\"},\n",
    "    # 나머지 카페들...\n",
    "]\n",
    "\n",
    "def crawl_images(cafe_name):\n",
    "    # 카페명을 URL에 맞게 인코딩\n",
    "    encoded_cafe_name = urllib.parse.quote(cafe_name)\n",
    "    url = search_url.format(encoded_cafe_name)\n",
    "\n",
    "    # 네이버 검색 결과 페이지 요청\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve search results for {cafe_name}\")\n",
    "        return []\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 첫 번째 selector로 이미지 태그를 선택하여 src 속성 추출\n",
    "    image_tags_1 = soup.select('img.K0PDV._div')\n",
    "    image_urls_1 = [img['src'] for img in image_tags_1 if 'src' in img.attrs]\n",
    "\n",
    "    # 첫 번째 리스트의 마지막 이미지를 제외\n",
    "    if image_urls_1:\n",
    "        image_urls_1 = image_urls_1[:-1]\n",
    "\n",
    "    # 두 번째 selector로 음식 사진 이미지 태그를 선택하여 src 속성 추출\n",
    "    # 주어진 XPath에 해당하는 부분을 탐색\n",
    "    ul_element = soup.select_one('#place-main-section-root > div > div:nth-child(4) > div.place_section_content > ul')\n",
    "    if ul_element:\n",
    "        image_tags_2 = ul_element.select('div.lazyload-wrapper img')\n",
    "        image_urls_2 = [img['src'] for img in image_tags_2 if 'src' in img.attrs]\n",
    "    else:\n",
    "        image_urls_2 = []\n",
    "\n",
    "    # 두 리스트를 합쳐서 반환\n",
    "    all_image_urls = image_urls_1 + image_urls_2\n",
    "    return all_image_urls\n",
    "\n",
    "# 각 카페별로 이미지 크롤링 수행\n",
    "for cafe in cafes:\n",
    "    cafe_name = cafe[\"카페명\"]\n",
    "    print(f\"Crawling images for: {cafe_name}\")\n",
    "    image_urls = crawl_images(cafe_name)\n",
    "    for idx, url in enumerate(image_urls):\n",
    "        print(f\"Image {idx + 1}: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling images for: 오푸 성수\n",
      "Failed to retrieve search results for 오푸 성수\n",
      "Crawling images for: 모센즈스위트 성수\n",
      "Failed to retrieve search results for 모센즈스위트 성수\n",
      "Crawling images for: 어피스앤드피스 성수\n",
      "Failed to retrieve search results for 어피스앤드피스 성수\n",
      "Crawling images for: 베러초이스 성수\n",
      "Failed to retrieve search results for 베러초이스 성수\n",
      "Crawling images for: 에젤커피 성수\n",
      "Failed to retrieve search results for 에젤커피 성수\n",
      "Crawling images for: 라에비뉴 성수\n",
      "Failed to retrieve search results for 라에비뉴 성수\n",
      "Crawling images for: 나드에프앤비 성수\n",
      "Failed to retrieve search results for 나드에프앤비 성수\n",
      "Crawling images for: 카페시벳 성수\n",
      "Failed to retrieve search results for 카페시벳 성수\n",
      "Crawling images for: 리얼 성수\n",
      "Failed to retrieve search results for 리얼 성수\n",
      "Crawling images for: 로우키 성수\n",
      "Failed to retrieve search results for 로우키 성수\n",
      "Crawling images for: 니드 성수\n",
      "Failed to retrieve search results for 니드 성수\n",
      "Crawling images for: 높은산 성수\n",
      "Failed to retrieve search results for 높은산 성수\n",
      "Crawling images for: 라스베이글 성수\n",
      "Failed to retrieve search results for 라스베이글 성수\n",
      "Crawling images for: 언니커피 성수\n",
      "Failed to retrieve search results for 언니커피 성수\n",
      "Crawling images for: 파티세리후르츠 성수\n",
      "Failed to retrieve search results for 파티세리후르츠 성수\n",
      "Crawling images for: 브로벨커피 성수\n",
      "Failed to retrieve search results for 브로벨커피 성수\n",
      "Crawling images for: ONE BEAN카페 성수\n",
      "Failed to retrieve search results for ONE BEAN카페 성수\n",
      "Crawling images for: 스텀필즈커피 성수\n",
      "Failed to retrieve search results for 스텀필즈커피 성수\n",
      "Crawling images for: 도토루커피OS 성수\n",
      "Failed to retrieve search results for 도토루커피OS 성수\n",
      "Crawling images for: 카페수다 성수\n",
      "Failed to retrieve search results for 카페수다 성수\n",
      "Crawling images for: 팔롬비니카페테리아 성수\n",
      "Failed to retrieve search results for 팔롬비니카페테리아 성수\n",
      "Crawling images for: 카페조이 성수\n",
      "Failed to retrieve search results for 카페조이 성수\n",
      "Crawling images for: 투달러스커피 성수\n",
      "Failed to retrieve search results for 투달러스커피 성수\n",
      "Crawling images for: Cafelashower 성수\n",
      "Failed to retrieve search results for Cafelashower 성수\n",
      "Crawling images for: 카페아모렘 성수\n",
      "Failed to retrieve search results for 카페아모렘 성수\n",
      "Crawling images for: 예빈당 성수\n",
      "Failed to retrieve search results for 예빈당 성수\n",
      "Crawling images for: 피어커피 성수\n",
      "Failed to retrieve search results for 피어커피 성수\n",
      "Crawling images for: 브루잉세레모니 성수\n",
      "Failed to retrieve search results for 브루잉세레모니 성수\n",
      "Crawling images for: 이트앤드링크 성수\n",
      "Failed to retrieve search results for 이트앤드링크 성수\n",
      "Crawling images for: 아이오쓰리에이스하이앤드점 성수\n",
      "Failed to retrieve search results for 아이오쓰리에이스하이앤드점 성수\n",
      "Crawling images for: 성수정원 성수\n",
      "Failed to retrieve search results for 성수정원 성수\n",
      "Crawling images for: 마이쥬스 성수\n",
      "Failed to retrieve search results for 마이쥬스 성수\n",
      "Crawling images for: 예셰숄 성수\n",
      "Failed to retrieve search results for 예셰숄 성수\n",
      "Crawling images for: 봉봉 성수\n",
      "Failed to retrieve search results for 봉봉 성수\n",
      "Crawling images for: 글리터 성수\n",
      "Failed to retrieve search results for 글리터 성수\n",
      "Crawling images for: 삼옥 성수\n",
      "Failed to retrieve search results for 삼옥 성수\n",
      "Crawling images for: 카페리빈 성수\n",
      "Failed to retrieve search results for 카페리빈 성수\n",
      "Crawling images for: 원스카페 성수\n",
      "Failed to retrieve search results for 원스카페 성수\n",
      "Crawling images for: 유니드 성수\n",
      "Failed to retrieve search results for 유니드 성수\n",
      "Crawling images for: 퓨엘커피 성수\n",
      "Failed to retrieve search results for 퓨엘커피 성수\n",
      "Crawling images for: 커피사피엔스성수우림점 성수\n",
      "Failed to retrieve search results for 커피사피엔스성수우림점 성수\n",
      "Crawling images for: 키쿠키앤커피성수 성수\n",
      "Failed to retrieve search results for 키쿠키앤커피성수 성수\n",
      "Crawling images for: 와이덴 성수\n",
      "Failed to retrieve search results for 와이덴 성수\n",
      "Crawling images for: 구테로이테성수센트럴키친 성수\n",
      "Failed to retrieve search results for 구테로이테성수센트럴키친 성수\n",
      "Crawling images for: 그레이덕 성수\n",
      "Failed to retrieve search results for 그레이덕 성수\n",
      "Crawling images for: 누와 성수\n",
      "Failed to retrieve search results for 누와 성수\n",
      "Crawling images for: 카페소림 성수\n",
      "Failed to retrieve search results for 카페소림 성수\n",
      "Crawling images for: 커피냅로스터스성수 성수\n",
      "Failed to retrieve search results for 커피냅로스터스성수 성수\n",
      "Crawling images for: 도렐 성수점 성수\n",
      "Failed to retrieve search results for 도렐 성수점 성수\n",
      "Crawling images for: 오우드 성수 성수\n",
      "Failed to retrieve search results for 오우드 성수 성수\n",
      "Crawling images for: 기와르\n",
      "Failed to retrieve search results for 기와르\n",
      "Crawling images for: 베티버 성수\n",
      "Failed to retrieve search results for 베티버 성수\n",
      "Crawling images for: Pauline CoffeeBar 성수\n",
      "Failed to retrieve search results for Pauline CoffeeBar 성수\n",
      "Crawling images for: 누데이크 성수\n",
      "Failed to retrieve search results for 누데이크 성수\n",
      "Crawling images for: 젤라또투유 성수\n",
      "Failed to retrieve search results for 젤라또투유 성수\n",
      "Crawling images for: 마를리 성수\n",
      "Failed to retrieve search results for 마를리 성수\n",
      "Crawling images for: 어니언 성수 성수\n",
      "Failed to retrieve search results for 어니언 성수 성수\n",
      "Crawling images for: 쎈느Scene 성수\n",
      "Failed to retrieve search results for 쎈느Scene 성수\n",
      "Crawling images for: 아이오쓰리 에이스하이엔드점 성수\n",
      "Failed to retrieve search results for 아이오쓰리 에이스하이엔드점 성수\n",
      "Crawling images for: 카멜커피 성수점 성수\n",
      "Failed to retrieve search results for 카멜커피 성수점 성수\n",
      "Crawling images for: 스프레이하우스 성수\n",
      "Failed to retrieve search results for 스프레이하우스 성수\n",
      "Crawling images for: 야페 성수\n",
      "Failed to retrieve search results for 야페 성수\n",
      "Crawling images for: 프레이커피바 성수\n",
      "Failed to retrieve search results for 프레이커피바 성수\n",
      "Crawling images for: 러프러프 성수\n",
      "Failed to retrieve search results for 러프러프 성수\n",
      "Crawling images for: 스트랏 성수\n",
      "Failed to retrieve search results for 스트랏 성수\n",
      "Crawling images for: 업.사이드 성수\n",
      "Failed to retrieve search results for 업.사이드 성수\n",
      "Crawling images for: 카페,바로 성수\n",
      "Failed to retrieve search results for 카페,바로 성수\n",
      "Crawling images for: 훔볼트 성수\n",
      "Failed to retrieve search results for 훔볼트 성수\n",
      "Crawling images for: 그레이박스카페 성수\n",
      "Failed to retrieve search results for 그레이박스카페 성수\n",
      "Crawling images for: 성수동대림창고갤러리 성수\n",
      "Failed to retrieve search results for 성수동대림창고갤러리 성수\n",
      "Crawling images for: 리브릭 성수\n",
      "Failed to retrieve search results for 리브릭 성수\n",
      "Crawling images for: 굴림 성수\n",
      "Failed to retrieve search results for 굴림 성수\n",
      "Crawling images for: 하루앤원데이 성수\n",
      "Failed to retrieve search results for 하루앤원데이 성수\n",
      "Crawling images for: 플록스phlox 성수\n",
      "Failed to retrieve search results for 플록스phlox 성수\n",
      "Crawling images for: 아쿠아산타성수카페 성수\n",
      "Failed to retrieve search results for 아쿠아산타성수카페 성수\n",
      "Crawling images for: 앙골로에스프레소 성수\n",
      "Failed to retrieve search results for 앙골로에스프레소 성수\n",
      "Crawling images for: 창창커피 성수\n",
      "Failed to retrieve search results for 창창커피 성수\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import json\n",
    "import os\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_file_path = '/Users/macbook/Desktop/numbered_cafes.json'\n",
    "\n",
    "# 이미지 저장 경로\n",
    "image_save_path = '/Users/macbook/Desktop/cafe_images'\n",
    "\n",
    "# 디렉토리가 없으면 생성\n",
    "if not os.path.exists(image_save_path):\n",
    "    os.makedirs(image_save_path)\n",
    "\n",
    "# JSON 파일에서 카페 목록 로드\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    cafes = json.load(f)\n",
    "\n",
    "# 네이버 모바일 검색 URL 패턴\n",
    "search_url = \"https://m.search.naver.com/search.naver?sm=mtp_hty.top&where=m&query={}\"\n",
    "\n",
    "def crawl_images(cafe_name):\n",
    "    # 카페명을 URL에 맞게 인코딩\n",
    "    encoded_cafe_name = requests.utils.quote(cafe_name)\n",
    "    url = search_url.format(encoded_cafe_name)\n",
    "\n",
    "    # 네이버 검색 결과 페이지 요청\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve search results for {cafe_name}\")\n",
    "        return []\n",
    "\n",
    "    # lxml의 html parser를 이용하여 HTML 파싱\n",
    "    tree = html.fromstring(response.content)\n",
    "\n",
    "    # XPath로 모든 <div class=\"place_thumb\"> 요소 찾기\n",
    "    img_xpath = '//*[@id=\"place-main-section-root\"]/div/div[4]/div[1]/ul//div[@class=\"place_thumb\"]/img'\n",
    "    image_tags = tree.xpath(img_xpath)\n",
    "\n",
    "    # img 태그의 src 속성 추출\n",
    "    image_urls = [img.get('src') for img in image_tags if img.get('src')]\n",
    "\n",
    "    # 반환된 이미지 URL 리스트 출력\n",
    "    return image_urls\n",
    "\n",
    "# 각 카페별로 이미지 크롤링 수행\n",
    "for cafe in cafes:\n",
    "    cafe_name = cafe[\"카페명\"]\n",
    "    print(f\"Crawling images for: {cafe_name}\")\n",
    "    image_urls = crawl_images(cafe_name)\n",
    "    \n",
    "    for idx, url in enumerate(image_urls):\n",
    "        print(f\"Image {idx + 1}: {url}\")\n",
    "        # 이미지 다운로드 및 저장\n",
    "        img_data = requests.get(url).content\n",
    "        image_filename = os.path.join(image_save_path, f\"{cafe_name}_{idx + 1}.jpg\")\n",
    "        with open(image_filename, 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "        print(f\"Saved image {idx + 1} for {cafe_name} to {image_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 이미지 코드!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling images for: 오푸 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230418_206%2F1681744751969cj4AO_PNG%2F%25BD%25BA%25C5%25A9%25B8%25B0%25BC%25A6_2023-04-18_%25BF%25C0%25C0%25FC_12.17.59.png\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231208_266%2F1702014763303lqL8W_JPEG%2F%25C5%25AB%25C4%25A7%25B4%25EB%25B9%25DD.jpg\n",
      "Crawling images for: 모센즈스위트 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221117_90%2F1668645854289hCaW0_JPEG%2FKakaoTalk_Photo_2022-11-17-09-43-51_004.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230614_131%2F1686730256947WWo2u_JPEG%2FIMG_1474.JPG\n",
      "Crawling images for: 어피스앤드피스 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221104_141%2F1667490238722LTX9v_JPEG%2F09686467-6FB1-4A8E-BD18-0E13189A0106.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221104_171%2F1667490238901loNjz_JPEG%2F8759412A-A484-430F-9A9A-87CDA4F83DCB.jpeg\n",
      "Crawling images for: 베러초이스 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzEwMjlfMTk3%2FMDAxNjk4NTIyMDQ3OTg3.XlqGh4CGHr1jZnET-Qnoi6eikiuqiLutjHVMFZrzTGMg.AnOCM19TBrR3DqWmkX76i8k9MmfxRJTeht1kAChiC6Qg.JPEG%2Fupload_d90a8902f427b11381737ec0feaea029.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzEwMjhfMTk1%2FMDAxNjk4NDMzODU3MzM4.7O1Vbv8rfYsyA7C-w216W751ecLeKPIB_OuhVx2vwIgg.5FOH3Oq9heNq3jXp40NV9drLfYqktbT324j2zumtLpwg.JPEG%2Fupload_af2de3b02b11e2998eb345c7892d6afd.jpeg\n",
      "Crawling images for: 에젤커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20160704_291%2F1467624040635R3duy_JPEG%2F176654585060355_0.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20160704_266%2F1467624040795tSme4_JPEG%2F176654585060355_1.jpeg\n",
      "Crawling images for: 라에비뉴 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20220731_4%2F1659242143584YCgCt_JPEG%2FKakaoTalk_20220731_133127291_04.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230621_65%2F1687302843369mrSsR_JPEG%2FKakaoTalk_20230602_160243655.jpg\n",
      "Crawling images for: 나드에프앤비 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzA3MTBfMTY5%2FMDAxNjg4OTc0NDA4NDMx.C7qZE8mvRHrSUeY-ST-cuhUAajrUj4ykQrTEq9r-aigg.mSXepKbUWSyeSxhUFsUPOKzhqALGqlw2O8qFHFr2-Tgg.JPEG%2F20230710_150205.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzA1MTBfMjU0%2FMDAxNjgzNjg4OTkyNzgy.iHBzlrSnZYrG69bywjVQJ_UdX0MvPCSnju8hK-rCXn4g.vRUJPQc4ehpNXAVbxkKDFwTOpZdsMf4OosxfGnUxarAg.JPEG%2F20230510_110501.jpg\n",
      "Crawling images for: 카페시벳 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20150901_118%2F1441057048652sEjh3_JPEG%2FSUBMIT_1319793898174_20604985.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20150901_173%2F1441057048841Kfal8_JPEG%2FSUBMIT_1319793909536_20604985.jpg\n",
      "Crawling images for: 리얼 성수\n",
      "Crawling images for: 로우키 성수\n",
      "Crawling images for: 니드 성수\n",
      "Crawling images for: 높은산 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240328_53%2F1711591247893xWiO2_JPEG%2FKakaoTalk_Photo_2024-03-28-11-00-36_003.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240328_78%2F1711591247752bP8ds_JPEG%2FKakaoTalk_Photo_2024-03-28-11-00-36_002.jpeg\n",
      "Crawling images for: 라스베이글 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230704_276%2F1688438174547kCXrE_JPEG%2FIMG_0925.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230704_191%2F1688438174290HQ1vH_JPEG%2FIMG_1049.jpeg\n",
      "Crawling images for: 언니커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20181207_238%2F1544144891265a3q7p_JPEG%2FsHtp8Oi2T-acOXurcBXp0ySk.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20200111_77%2F1578728160210TxKQD_JPEG%2FbONo1QvtqEyCD8StgbPR9QGh.jpg\n",
      "Crawling images for: 파티세리후르츠 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240330_249%2F1711803271160KRsdJ_JPEG%2F1711803145068.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240330_141%2F1711803299951ivrIy_JPEG%2F1711258045356.jpg\n",
      "Crawling images for: 브로벨커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230428_15%2F1682646978346ld801_JPEG%2FKakaoTalk_20230425_145311310_06.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230308_287%2F1678260060019z1jYy_JPEG%2F0BEAF950-5707-4499-B235-34E000BBE4A5.jpeg\n",
      "Crawling images for: ONE BEAN카페 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20200303_123%2F1583221441986mzhWg_JPEG%2F8HuQt-Zoq6Jrar_IHnJHsqJu.jpg\n",
      "Crawling images for: 스텀필즈커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20210421_6%2F16189753761904xBMv_JPEG%2F%25BD%25BA%25C5%25D2%25C7%25CA%25C1%25EE%25C4%25BF%25C7%25C7%25B7%25CE%25B0%25ED%2528%25B3%25D7%25C0%25CC%25B9%25F6%25C7%25C3%25B7%25B9%25C0%25CC%25BD%25BA%2529.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzEwMThfNzQg%2FMDAxNjk3NTg4MDAzMjc5._cGmLo382rG52x6tc9UDVbpwHYxrAelRwOQZMtjLIhQg.yZNBzbAS9q5yqcVfpWUfnabyNvKzvZrasTja_2AsmU0g.JPEG%2Fupload_67b803f33f44fb2482721f045e4311fb.jpg\n",
      "Crawling images for: 도토루커피OS 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240814_234%2F1723614034871q9ABg_JPEG%2FKakaoTalk_20240813_204744317_05.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240814_226%2F1723615454142mWL5d_PNG%2F%25C8%25AD%25B8%25E9_%25C4%25B8%25C3%25B3_2024-08-14_150311.png\n",
      "Crawling images for: 카페수다 성수\n",
      "Crawling images for: 팔롬비니카페테리아 성수\n",
      "Crawling images for: 카페조이 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230908_180%2F1694149042388Craxw_JPEG%2FIMG_4409.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240215_30%2F1707980608675YY4Xg_JPEG%2FIMG_2836.jpeg\n",
      "Crawling images for: 투달러스커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20200910_220%2F1599727086900BGwEw_JPEG%2Fimage.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20200910_291%2F1599727111906REmTu_JPEG%2Fimage.jpg\n",
      "Crawling images for: Cafelashower 성수\n",
      "Crawling images for: 카페아모렘 성수\n",
      "Crawling images for: 예빈당 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240504_139%2F1714805617063R2S6Q_JPEG%2FIMG_4482.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240504_262%2F17148070165581UA3X_JPEG%2FIMG_9053.jpeg\n",
      "Crawling images for: 피어커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20150901_18%2F14410667129099Xnoy_JPEG%2FSUBMIT_1415291332257_33704135.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=http%3A%2F%2Fblogfiles.naver.net%2F20160212_47%2Fyunsoo5024_1455205437918PiROp_JPEG%2FDSC01054.JPG\n",
      "Crawling images for: 브루잉세레모니 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20190905_40%2F1567682758061hYHXI_JPEG%2FAj0VUn64zruquzR-GRoHDbrO.JPG.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20190905_158%2F1567682769416SOsHo_JPEG%2FqutHqN0hKfYpqbt4RCBYgSQz.JPG.jpg\n",
      "Crawling images for: 이트앤드링크 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240521_116%2F1716260761579SJFRT_JPEG%2FIMG_5652.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240521_26%2F1716260769125zRMMc_JPEG%2FIMG_5650.jpeg\n",
      "Crawling images for: 아이오쓰리에이스하이앤드점 성수\n",
      "Crawling images for: 성수정원 성수\n",
      "Crawling images for: 마이쥬스 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzAxMDlfMTkw%2FMDAxNjczMjM0MjkyNzA2.gJZX_CvQTbWNnutHZJqbGUDmRnP2wpu-6OaKEz1BBWUg.-oKcSY6HnwO2vvqEXiXZDtKIHen7PjtX6qsoeNrqVTkg.JPEG%2FA1EA194C-42A9-4BE1-80B6-4B8790D7584E.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzAyMjFfMjUg%2FMDAxNjc2OTc1MzMxMjk5.GDQ0oWBnpHidJ750r6RPNCOJK4dOaNwS1VTs6T7rxuYg.0x-qws2mF4bRc9Sz5zoL-3vPhjIy0U07yqz1uQtM9Owg.JPEG%2F335CD8C4-0496-427B-A234-E20CDD6DA1B2.jpeg\n",
      "Crawling images for: 예셰숄 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230509_261%2F1683619988401LCugA_JPEG%2FKakaoTalk_20230509_170944310.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230509_277%2F1683619988695Y7Xbl_JPEG%2FKakaoTalk_20230509_170944310_02.jpg\n",
      "Crawling images for: 봉봉 성수\n",
      "Crawling images for: 글리터 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240324_70%2F1711258295105uA2kx_JPEG%2F99513C02-FA36-4ED4-8C58-DB26F881AFAF.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240526_287%2F1716657732604PRYHf_JPEG%2FIMG_7673.jpeg\n",
      "Crawling images for: 삼옥 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230216_235%2F16764808594070JSFc_JPEG%2FA48C3D87-9462-487D-8453-A80AF0BA0E62.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230506_160%2F1683347326560K10No_JPEG%2FIMG_9577.JPG\n",
      "Crawling images for: 카페리빈 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzA0MjNfMTI5%2FMDAxNjgyMjU1MzEwMTc4.GmJOGAunSlrRiWSdJ6oJYCzh7Ob7NpfPDRQmwdKhFsAg.a4OPrWaYcVVsdQL2B5-g2MQELr5LPyCeiYLbQRIXzFYg.JPEG%2FIMG_7477.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMjA1MjVfODIg%2FMDAxNjUzNDQ5Mzk5ODk4.0_y9qrWF_WiSFZ0TmzKJXvLKtuZy8p_cAAmBjRwThi0g.AsmfTm6Dp-12hEETBVHkk9DJ8UC0xasxiVCJB1qYaNkg.JPEG%2Fupload_095f8133df0f29f77dc2978c5d8d3efa.jpg\n",
      "Crawling images for: 원스카페 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221026_246%2F1666789172141HUjbq_JPEG%2F%25BF%25F8%25BD%25BA%25C4%25AB%25C6%25E42.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221026_157%2F1666791040656pXAgV_JPEG%2F%25B8%25DE%25C0%25CE.jpg\n",
      "Crawling images for: 유니드 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221230_214%2F1672383999592oy3XX_JPEG%2FIMG_20221220_110546_793.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231023_275%2F16980426648472oCWr_JPEG%2FMTXX_MH20231003_180143352.jpg\n",
      "Crawling images for: 퓨엘커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231017_25%2F1697542938167e1B8m_JPEG%2FIMG_9489.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20200728_250%2F1595903045483n65CP_JPEG%2FHP3aEvyS0MrH0wyNjvGvK3xn.jpeg.jpg\n",
      "Crawling images for: 커피사피엔스성수우림점 성수\n",
      "Crawling images for: 키쿠키앤커피성수 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230226_68%2F1677396053000MkD5E_JPEG%2F1677395941068.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230226_6%2F1677395864302yhSpz_JPEG%2F1677395776825.jpg\n",
      "Crawling images for: 와이덴 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240506_275%2F1714978058883BCCG2_JPEG%2FIMG_7078.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231109_188%2F1699492625725WVlWP_JPEG%2FKakaoTalk_20231108_075848179.jpg\n",
      "Crawling images for: 구테로이테성수센트럴키친 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231004_299%2F16963925069835qnoK_JPEG%2F1696342808239.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230905_70%2F1693920111344hlNR0_JPEG%2FIMG_0706.jpeg\n",
      "Crawling images for: 그레이덕 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240116_21%2F1705401848483hMSkj_JPEG%2FKakaoTalk_20230902_111128715.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240116_205%2F1705402536760pbMcY_JPEG%2FKakaoTalk_20240116_195450967_03.jpg\n",
      "Crawling images for: 누와 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240125_45%2F17061666451905qb0h_JPEG%2F1000054522.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240126_291%2F1706246242210DHVss_JPEG%2F1000054491.jpg\n",
      "Crawling images for: 카페소림 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240417_165%2F1713332762633CdhiG_JPEG%2FIMG_8445.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240417_110%2F1713332760610l0mWP_JPEG%2FIMG_8431.jpeg\n",
      "Crawling images for: 커피냅로스터스성수 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231004_169%2F1696374162543HV2rr_JPEG%2FDSCF4170.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzEwMTdfOTQg%2FMDAxNjk3NTE4MDA3MzI0.59mVOMYuf1CV2MxOYwUcXhu4ToXZZTHJlXYazKWtvkQg.hHat1IfGejcKlnGK8eWSVEYTv-MXC0ptvPJzVDd4T0Mg.JPEG%2F8604B6DD-2A9C-43BE-AC4B-D3DA1C68AB96.jpeg\n",
      "Crawling images for: 도렐 성수점 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20181026_249%2F1540537897309RYsmp_JPEG%2Fnlgx9s93vcTdGl71Iad8c5ty.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20181026_235%2F1540537922107p8Rr2_JPEG%2FJ_rIdrqRgrnI9evZxrGqbfMG.jpg\n",
      "Crawling images for: 오우드 성수 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230205_68%2F16755836463620c468_JPEG%2Foude_2nd__%25284%2529.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230205_54%2F1675583642319gUxup_JPEG%2Foude_2nd__%25286%2529.jpg\n",
      "Crawling images for: 기와르\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240530_213%2F1717056967301XLUx5_JPEG%2FIMG_2641.JPG\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240302_272%2F1709346181368tMX0w_JPEG%2FIMG_1876.JPG\n",
      "Crawling images for: 베티버 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20231213_6%2F17024589869364SbvR_JPEG%2FIMG_0087.JPG\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230802_6%2F1690943199432pIBVT_JPEG%2FIMG_0164.jpeg\n",
      "Crawling images for: Pauline CoffeeBar 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240129_290%2F1706495635439xhBXk_JPEG%2FIMG_0219.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240404_73%2F17122092474567gudG_JPEG%2FIMG_3293.jpeg\n",
      "Crawling images for: 누데이크 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20220805_110%2F1659686316773D5xW5_JPEG%2FKakaoTalk_20220802_143532665_03.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20220805_209%2F1659689653239Qst8x_PNG%2F%25B0%25F8%25B0%25A33.png\n",
      "Crawling images for: 젤라또투유 성수\n",
      "Crawling images for: 마를리 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20210126_163%2F16116223547400HwjY_JPEG%2FxNii6KO-ZKnso094qkfWlBdH.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=http%3A%2F%2Fblogfiles.naver.net%2FMjAxODA4MTNfMjgy%2FMDAxNTM0MTQ4MjE0MDE1.wV0r6ukCgkkDVZtjy6YEE46Q3Ksng1afnyj7hcgldHsg.GeFQVkRjwGRrWqgKaXdgAajBlPDLcOA8E_bwKnehV5sg.JPEG.creameda%2F20180708_124202.jpg\n",
      "Crawling images for: 어니언 성수 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20230612_255%2F1686562488552F0Omh_PNG%2FLOGO.png\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20190204_269%2F1549212634045uJAvX_PNG%2FZfpnq_GUADvxtxA8DK6xvfOK.png\n",
      "Crawling images for: 쎈느Scene 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221114_47%2F1668404667321rlk6m_JPEG%2F%25B4%25EB%25C1%25F6_74x-100.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221110_24%2F1668057324177EbCIM_JPEG%2Fgreemjeong_r2_0005_%25C3%25D6%25C1%25BE.jpg\n",
      "Crawling images for: 아이오쓰리 에이스하이엔드점 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20210908_186%2F1631081023455SCOaT_JPEG%2FIlzsGpUbHmFwMaY2OWabrCR-.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240314_73%2F1710396381853ePcWb_JPEG%2FKakaoTalk_20231109_174039967.jpg\n",
      "Crawling images for: 카멜커피 성수점 성수\n",
      "Crawling images for: 스프레이하우스 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221129_21%2F1669711320899XIL0u_JPEG%2FCA4ABFAC-6D75-41F8-92A5-7AF7B25A8007.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20221129_247%2F1669711320947aFOdO_JPEG%2F3B032BF1-BF7B-4397-B4AF-BEA9E58E79DC.jpeg\n",
      "Crawling images for: 야페 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20211120_191%2F1637374337261xVHGy_JPEG%2F20211112_182159.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzEwMTdfMzAg%2FMDAxNjk3NDcxODUzMDM5.Twb8UOMGYkmaSg-HwIW--eyY2Kyso-qdvBdiKP_uEeUg.Km5gkanoKhZcIHNdWT-U4uobfGtng91XNHHIMsqchFUg.JPEG%2Fupload_c9deacc6ed8c0a01f1dda2bfe2243fef.jpeg\n",
      "Crawling images for: 프레이커피바 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20210306_294%2F1615025058478HfUuC_JPEG%2F1tY4CxIpBorCstxjYq9gwmEG.jpeg.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20210306_25%2F1615025133391VXs4n_JPEG%2FX2GYIf5a0XjLj_RkLmAmRon-.jpeg.jpg\n",
      "Crawling images for: 러프러프 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fvideo-phinf.pstatic.net%2F20240527_85%2F1716744092366trOmH_JPEG%2Fsc35lrD7Nb_03.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240220_94%2F1708359415322f6v2d_JPEG%2FKakaoTalk_20240219_121307746_24.jpg\n",
      "Crawling images for: 스트랏 성수\n",
      "Crawling images for: 업.사이드 성수\n",
      "Crawling images for: 카페,바로 성수\n",
      "Crawling images for: 훔볼트 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20181213_69%2F1544685545323Pjqcd_JPEG%2F20a_cDU-t-P-SsdDp0ho5A1Y.JPG.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20181213_23%2F15446856373189kfkJ_JPEG%2F70gZKbQVozfKlwT9INtRCsNi.jpg\n",
      "Crawling images for: 그레이박스카페 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20220106_202%2F1641431129368DmiWv_JPEG%2Fimage.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20220111_133%2F16418647533860GOGV_JPEG%2F%25B8%25AE%25B4%25BA%25BE%25F3_%25BE%25C8%25B3%25BB.jpg\n",
      "Crawling images for: 성수동대림창고갤러리 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20220705_23%2F1656959975816l90nE_JPEG%2FKakaoTalk_Photo_2022-07-05-03-39-03_004.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20220705_65%2F1656959975574rVrxW_JPEG%2FKakaoTalk_Photo_2022-07-05-03-39-02_001.jpeg\n",
      "Crawling images for: 리브릭 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20191107_87%2F1573105272425VwTnv_JPEG%2F-z4GxVTYDI2cJK8psJ7eEIEr.jpeg.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240119_51%2F17056422707134J4YN_JPEG%2FIMG_3900.jpeg\n",
      "Crawling images for: 굴림 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20211203_92%2F16384629525191yXBs_JPEG%2FCC24B3C5-A15C-44F8-B2D4-93CBB112DEFC.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20211203_242%2F1638462951400GU8Q0_JPEG%2F3AC1B6D3-4F8A-4CA1-918C-8BE1A19C995D.jpeg\n",
      "Crawling images for: 하루앤원데이 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240306_280%2F1709699524428HEOiv_JPEG%2FKakaoTalk_Photo_2024-03-05-16-20-53_001.jpeg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20240306_57%2F1709709953673HaY0r_JPEG%2FIMG_5372.JPG\n",
      "Crawling images for: 플록스phlox 성수\n",
      "Crawling images for: 아쿠아산타성수카페 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fvideo-phinf.pstatic.net%2F20240803_46%2F1722672490304lSKxy_JPEG%2FLZHY4G9OFa_03.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fvideo-phinf.pstatic.net%2F20240725_258%2F1721895560784GGRCo_JPEG%2FW8yPMt7RAX_03.jpg\n",
      "Crawling images for: 앙골로에스프레소 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20201117_209%2F1605594986249zAiAd_JPEG%2F6PtYFavXVyQNFiZdx5w6EDPa.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20201117_92%2F1605595040096IVtAO_JPEG%2F6EI1-Cb8vadsejOEwqFRmKZQ.jpg\n",
      "Crawling images for: 창창커피 성수\n",
      "Image 1: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20210319_271%2F1616122667934s9gne_JPEG%2FrOtMDkVrlrLv-1yTm3ZIdJR4.jpeg.jpg\n",
      "Image 2: https://search.pstatic.net/common/?autoRotate=true&quality=95&type=w750&src=https%3A%2F%2Fpup-review-phinf.pstatic.net%2FMjAyMzEwMjZfMjU4%2FMDAxNjk4MzI1MzE0MDE2.pRXuun-RFNnKEuFH5S5yGYhkyQ7SULEXRfJEpL7TtNsg.pjCnDRaFlKFk96fOkhla7JNL1kGpqcVqOe-bzBCKiTIg.JPEG%2Fupload_06451c7faac0801e2e4b73066018fcb3.jpeg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_file_path = '/Users/macbook/Desktop/numbered_cafes.json'\n",
    "\n",
    "# JSON 파일에서 카페 목록 로드\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    cafes = json.load(f)\n",
    "\n",
    "# 네이버 모바일 검색 URL 패턴\n",
    "search_url = \"https://m.search.naver.com/search.naver?sm=mtp_hty.top&where=m&query={}\"\n",
    "\n",
    "def crawl_images(cafe_name):\n",
    "    # 카페명을 URL에 맞게 인코딩\n",
    "    encoded_cafe_name = urllib.parse.quote(cafe_name)\n",
    "    url = search_url.format(encoded_cafe_name)\n",
    "\n",
    "    # 네이버 검색 결과 페이지 요청\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve search results for {cafe_name}\")\n",
    "        return []\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 첫 번째 selector로 이미지 태그를 선택하여 src 속성 추출\n",
    "    image_tags_1 = soup.select('img.K0PDV._div')\n",
    "    image_urls_1 = [img['src'] for img in image_tags_1 if 'src' in img.attrs]\n",
    "\n",
    "    # 첫 번째 리스트의 마지막 이미지를 제외\n",
    "    if image_urls_1:\n",
    "        image_urls_1 = image_urls_1[:-1]\n",
    "\n",
    "    # 두 번째 selector로 음식 사진 이미지 태그를 선택하여 src 속성 추출\n",
    "    ul_element = soup.select_one('#place-main-section-root > div > div:nth-child(4) > div.place_section_content > ul')\n",
    "    if ul_element:\n",
    "        image_tags_2 = ul_element.select('div.lazyload-wrapper img')\n",
    "        image_urls_2 = [img['src'] for img in image_tags_2 if 'src' in img.attrs]\n",
    "    else:\n",
    "        image_urls_2 = []\n",
    "\n",
    "    # 두 리스트를 합쳐서 반환\n",
    "    all_image_urls = image_urls_1 + image_urls_2\n",
    "    return all_image_urls\n",
    "\n",
    "# 각 카페별로 이미지 크롤링 수행\n",
    "for cafe in cafes:\n",
    "    cafe_name = cafe[\"카페명\"]\n",
    "    print(f\"Crawling images for: {cafe_name}\")\n",
    "    image_urls = crawl_images(cafe_name)\n",
    "    for idx, url in enumerate(image_urls):\n",
    "        print(f\"Image {idx + 1}: {url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인스타그램 피드 이미지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m image_src \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 이미지 다운로드\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_src\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    481\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    483\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 484\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:367\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:438\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# 크롤링할 인스타그램 url 설정\n",
    "url = \"https://www.instagram.com/mohssenssweet_seongsu/\"\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 게시물 내 이미지 클래스명으로 찾기\n",
    "image = driver.find_element(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장\n",
    "image_src = image.get_attribute('src')\n",
    "\n",
    "# 이미지 다운로드\n",
    "response = requests.get(image_src)\n",
    "filename = 'image.jpg'\n",
    "with open(filename, 'wb+') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"사진 수집이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인스타 피드 이미지 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 오푸 성수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 '오푸_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# 크롤링할 인스타그램 url 설정\n",
    "url = \"https://www.instagram.com/oafuoafu\"\n",
    "\n",
    "# 이미지를 저장할 폴더 이름 설정\n",
    "folder_name = \"오푸_instagram_images\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    response = requests.get(image_src)\n",
    "    filename = os.path.join(folder_name, f'오푸_image_{idx}.jpg')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 모센즈스위트 성수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 '모센즈스위트_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# 크롤링할 인스타그램 url 설정\n",
    "url = \"https://www.instagram.com/mohssenssweet_seongsu/\"\n",
    "\n",
    "# 이미지를 저장할 폴더 이름 설정\n",
    "folder_name = \"모센즈스위트_instagram_images\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    response = requests.get(image_src)\n",
    "    filename = os.path.join(folder_name, f'모센즈스위트_image_{idx}.jpg')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# 크롤링할 인스타그램 url 설정\n",
    "url = \"https://www.instagram.com/mohssenssweet_seongsu/\"\n",
    "\n",
    "# 이미지를 저장할 폴더 이름 설정\n",
    "folder_name = \"모센즈스위트_instagram_images\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    response = requests.get(image_src)\n",
    "    filename = os.path.join(folder_name, f'모센즈스위트_image_{idx}.jpg')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 어피스앤드피스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 '어피스앤드피스_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# 크롤링할 인스타그램 url 설정\n",
    "url = \"https://www.instagram.com/apieceandpeace\"\n",
    "\n",
    "# 이미지를 저장할 폴더 이름 설정\n",
    "folder_name = \"어피스앤드피스_instagram_images\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    response = requests.get(image_src)\n",
    "    filename = os.path.join(folder_name, f'어피스앤드피스_image_{idx}.jpg')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 베러초이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 20장의 사진이 'instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# 크롤링할 인스타그램 url 설정\n",
    "url = \"https://www.instagram.com/betterchoice_korea\"\n",
    "\n",
    "# 이미지를 저장할 폴더 이름 설정\n",
    "folder_name = \"instagram_images\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 20\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src not in collected_images:\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    response = requests.get(image_src)\n",
    "    filename = os.path.join(folder_name, f'image_{idx}.jpg')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5 EZER Coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'EZER Coffee_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# 크롤링할 인스타그램 url 설정\n",
    "url = \"https://www.instagram.com/ezercoffee/\"\n",
    "\n",
    "# 이미지를 저장할 폴더 이름 설정\n",
    "folder_name = \"EZER Coffee_instagram_images\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    response = requests.get(image_src)\n",
    "    filename = os.path.join(folder_name, f'EZER Coffee_image_{idx}.jpg')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6 라에비뉴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/6_라에비뉴_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/laavenue_official_/\"\n",
    "\n",
    "# 이미지 파일명 관련 변수 설정\n",
    "num = '6'\n",
    "cafe_name = '라에비뉴'\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7 나드에프앤비, #8 카페시벳-- 직접 사진 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9 naver_review_9_성수동 리얼 로스팅 커피&디저트_1190505473.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m image_src \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image_src:  \u001b[38;5;66;03m# 이미지 소스가 존재하는 경우에만 다운로드 시도\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_src\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_name, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcafe_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_image_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# idx에 1을 더해서 1부터 시작\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_9_성수동 리얼 로스팅 커피&디저트_1190505473.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/seongsureal_official\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 naver_review_10_로우키_1393890643.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/10_로우키_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_10_로우키_1393890643.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/lowkey_coffee\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#11 naver_review_11_니드인_1935137830.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/11_니드인_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_11_니드인_1935137830.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/lowkey_coffee\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#12 naver_review_12_높은산_1081045129.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/12_높은산_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_12_높은산_1081045129.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/noppensan\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#13 naver_review_13_라스베이글 성수점_1173495456.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/13_라스베이글 성수점_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_13_라스베이글 성수점_1173495456.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/las.bagel/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#14 naver_review_14_언니커피_1346789087.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/14_언니커피_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_14_언니커피_1346789087.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/yejisun0812/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_15_파티세리 후르츠_1182897501.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/15_파티세리 후르츠_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_15_파티세리 후르츠_1182897501.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/patisserie.fruits/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_16_브로벨커피_1428046376.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/16_브로벨커피_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_16_브로벨커피_1428046376.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/brobellcoffee\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_17_ONE BEAN카페_1782682179.json -- 직접"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_18_스텀필즈커피_1765995009.json -- 직접"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_19_도토루커피os_37049427.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/19_도토루커피os_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_19_도토루커피os_37049427.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/coffeos\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_20_카페수다_34351850.json -- 직접\n",
    "naver_review_21_팔롬비니_1846703943.json -- 직접\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_22_카페조이_32812333.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/22_카페조이_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_22_카페조이_32812333.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/joecool_kkj\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_23_투달러스커피_75758743.json -- 직접\n",
    "naver_review_24_카페라샤워_1590690124.json -- 직접\n",
    "naver_review_25_카페아모렘_1403886445.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_review_26_예빈당_11861121.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/26_예빈당_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_26_예빈당_11861121.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/yebindang_cafe\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_27_피어커피_33704135.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/27_피어커피_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_27_피어커피_33704135.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/peer_coffee/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_28_브루잉 세레모니_1613470297.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/28_브루잉 세레모니_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_28_브루잉 세레모니_1613470297.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/brewingceremony/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_29_이트앤드링크 성수_1483166635.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/29_이트앤드링크 성수_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_29_이트앤드링크 성수_1483166635.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/eatanddrinkseoul\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_30_아이오쓰리 에이스하이엔드점_1623328599.json -- 직접\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_31_봄의정원 성수점_1502355065.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/31_봄의정원 성수점_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_31_봄의정원 성수점_1502355065.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/spring__garden_\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_32_마이쥬스 성수낙낙점_1626027648.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_33_예셰숄_1984160681.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/33_예셰숄_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_33_예셰숄_1984160681.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/yesyesyall_\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_34_쇼콜라쏭즈_1241528957.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/34_쇼콜라쏭즈_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_34_쇼콜라쏭즈_1241528957.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/chocolat111_\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_35_글리터_1973759403.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/35_글리터_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_35_글리터_1973759403.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/glitter_seongsu\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_36_삼옥_1297713401.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/36_삼옥_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_36_삼옥_1297713401.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/sam_ok.official\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_37_카페리빈 성수점_1879884818.json -- 직접"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_38_원스카페_1879463803.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_39_유니드카페_1577691489.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_40_퓨엘커피_1776731967.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_41_커피사피엔스 성수우림점_1824108106.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_42_키쿠키앤커피 성수_1716355636.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_43_와이덴 성수_1982767346.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_44_구테로이테 성수센트럴키친_1046248956.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_45_그레이덕_1167958425.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/45_그레이덕_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_45_그레이덕_1167958425.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/grayduck_41?utm_source=qr&igshid=MzNlNGNkZWQ4Mg%3D%3D\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_46_누와_1612076914.json --직접"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_47_카페소림_1194892405.json --직접"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_48_커피냅로스터스 성수_1355804064.json -- 25개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 25장의 사진이 'cafeinsta_images/48_커피냅로스터스 성수_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/coffeenap_roasters/\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_48_커피냅로스터스 성수_1355804064.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 25\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_49_도렐 성수점_1432336976.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/49_도렐 성수점_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_49_도렐 성수점_1432336976.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/dorrell_coffee/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_50_오우드 성수_1216172292.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 25장의 사진이 'cafeinsta_images/50_오우드 성수_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/oude_seoul\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_50_오우드 성수_1216172292.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 25\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_51_기와르_1273097610.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 25장의 사진이 'cafeinsta_images/51_기와르_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/_kiwaru\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_51_기와르_1273097610.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 25\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_52_베티버 성수_1383256753.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 25장의 사진이 'cafeinsta_images/52_베티버 성수_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/v.etiver\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_52_베티버 성수_1383256753.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 25\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_53_Pauline CoffeeBar_1215237779.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/53_Pauline CoffeeBar_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_53_Pauline CoffeeBar_1215237779.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/pauline_coffeebar/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_54_누데이크 성수_1691420621.json -- 직접"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_55_젤라또투유_1247801780.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 모든 사진이 'cafeinsta_images/55_젤라또투유_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_55_젤라또투유_1247801780.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정 (URL을 지정해야 함)\n",
    "url = \"https://www.instagram.com/seongsu_gelato2u/\"\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본 설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 클래스명으로 모든 이미지 요소 찾기\n",
    "images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "\n",
    "# 이미지 주소 저장 및 다운로드\n",
    "for idx, image in enumerate(images):\n",
    "    image_src = image.get_attribute('src')\n",
    "    if image_src:  # 이미지 소스가 존재하는 경우에만 다운로드 시도\n",
    "        response = requests.get(image_src)\n",
    "        filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')  # idx에 1을 더해서 1부터 시작\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 모든 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_56_마를리_742676592.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 25장의 사진이 'cafeinsta_images/56_마를리_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/marly.official_\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_56_마를리_742676592.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 25\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_57_어니언 성수_38561949.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_58_쎈느Scene_1030871168.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 25장의 사진이 'cafeinsta_images/58_쎈느Scene_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/sceneseoul_official\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_58_쎈느Scene_1030871168.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 25\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 9}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_59_아이오쓰리 에이스하이엔드점_1623328599.json -- 30번이랑 겹침"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_60_카멜커피 성수점_55585656.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/60_카멜커피 성수점_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/camelcoffee_kor/\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_60_카멜커피 성수점_55585656.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_61_스프레이하우스_1300253897.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/61_스프레이하우스_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/sprayhouse_cafe\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_61_스프레이하우스_1300253897.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_62_야페_1701590225.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/62_야페_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/cafe.yafe\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_62_야페_1701590225.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_63_프레이커피바 PCB서울_1852410455.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/63_프레이커피바 PCB서울_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/pcb_seoul\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_63_프레이커피바 PCB서울_1852410455.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_64_러프러프_1829908685.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/64_러프러프_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/rufruf_museum/\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_64_러프러프_1829908685.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_65_카페 스트랏_1410613160.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_66_업사이드커피_1259420360.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/66_업사이드커피_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/up.side_\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_66_업사이드커피_1259420360.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_67_카페바로_1916513487.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_68_훔볼트_1504347953.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_69_그레이박스_1949527561.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_70_성수동대림창고갤러리_37910590.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_71_리브릭_1424869222.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/71_리브릭_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/libreak\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_71_리브릭_1424869222.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_72_굴림_1397836032.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/72_굴림_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/goollimm\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_72_굴림_1397836032.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_73_하루앤원데이_38692829.json --직접"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_74_플록스_1515867867.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_75_아쿠아산타 성수카페_1517487358.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/75_아쿠아산타 성수카페_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/acqua__santa/\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_75_아쿠아산타 성수카페_1517487358.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_76_앙골로에스프레소_1066610472.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_77_창창커피_1005128677.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/77_창창커피_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/changchang_coffee\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_77_창창커피_1005128677.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_78_BNHR_1223354536.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/78_BNHR_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/bnhrcoffee\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_78_BNHR_1223354536.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_79_단과자_1177180342.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m collected_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(collected_images) \u001b[38;5;241m<\u001b[39m target_image_count:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# 현재 로드된 모든 이미지 요소 찾기\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# 새롭게 발견된 이미지 주소 저장\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:778\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    774\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    137\u001b[0m         method,\n\u001b[1;32m    138\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/daan_kkaka\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_79_단과자_1177180342.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    \n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_22_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_80_라니커피_1227111236.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_81_럭럭카페_1168976634.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_82_레이더 성수_1525007973.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_83_로우커피스탠드 성수점_1168698330.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/83_로우커피스탠드 성수점_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/rawcoffeestand_official\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_83_로우커피스탠드 성수점_1168698330.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_84_스테치_1180418614.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_86_앤드밀 성수점_1943210266.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/86_앤드밀 성수점_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/andmeal_sy\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_86_앤드밀 성수점_1943210266.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_88_어커_1560084717.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/88_어커_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/accurofficial\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_88_어커_1560084717.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_89_어퍼룸_1964635228.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/89_어퍼룸_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/upperroom_coffee_\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_89_어퍼룸_1964635228.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_90_어페어커피_1863706992.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/90_어페어커피_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/affaircoffee_\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_90_어페어커피_1863706992.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_91_에이투비 Cafe&Bar_1537971823.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 40장의 사진이 'cafeinsta_images/91_에이투비 Cafe&Bar_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/atob_cafeandbar\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_91_에이투비 Cafe&Bar_1537971823.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 40\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_92_오프커피_1921874344.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 50장의 사진이 'cafeinsta_images/92_오프커피_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/5ff_coffee\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_92_오프커피_1921874344.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 50\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_93_카페온유_1169957780.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 12장의 사진이 'cafeinsta_images/93_카페온유_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/_cafe_onu\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_93_카페온유_1169957780.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 12\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_94_유스트레스_1999678821.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_95_치카치카_37191703.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 30장의 사진이 'cafeinsta_images/95_치카치카_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/chika.seongsu\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_95_치카치카_37191703.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 30\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_96_카페메이_1210627765.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_97_카페크라비_1872719083.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_98_호두이즈월넛 HODOOISWALNUT_1362812488.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_99_커피베이 성동성수점_1573389383.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_100_커피식구성수센터_1447656721.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 30장의 사진이 'cafeinsta_images/100_커피식구성수센터_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/coffee.seekoo_seongsu\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_100_커피식구성수센터_1447656721.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 30\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_101_커피코코_1853990672.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_102_크레송_37392409.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 수집이 완료되었습니다. 총 30장의 사진이 'cafeinsta_images/102_크레송_instagram_images' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# 크롤링할 인스타그램 URL 설정\n",
    "url = \"https://www.instagram.com/cressong_\"\n",
    "\n",
    "# JSON 파일 이름 예시\n",
    "json_file_name = \"naver_review_102_크레송_37392409.json\"\n",
    "\n",
    "# JSON 파일 이름에서 num과 cafe_name 추출\n",
    "file_parts = json_file_name.split('_')\n",
    "num = file_parts[2]\n",
    "cafe_name = file_parts[3]\n",
    "\n",
    "# 이미지 저장 폴더 설정 (cafeinsta_images 폴더 내에 저장)\n",
    "base_folder = \"cafeinsta_images\"\n",
    "folder_name = os.path.join(base_folder, f\"{num}_{cafe_name}_instagram_images\")\n",
    "\n",
    "# 폴더가 존재하지 않을 경우 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 크롬 웹드라이버 구동 및 기본설정\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model, necessary for Colab\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# 이미지 수집 수와 스크롤 횟수 설정\n",
    "target_image_count = 30\n",
    "scroll_pause_time = 2  # 스크롤 후 대기 시간 (초)\n",
    "collected_images = set()\n",
    "\n",
    "while len(collected_images) < target_image_count:\n",
    "    # 현재 로드된 모든 이미지 요소 찾기\n",
    "    images = driver.find_elements(By.CLASS_NAME, \"x5yr21d.xu96u03.x10l6tqk.x13vifvy.x87ps6o.xh8yej3\")\n",
    "    # 새롭게 발견된 이미지 주소 저장\n",
    "    for image in images:\n",
    "        image_src = image.get_attribute('src')\n",
    "        if image_src and image_src not in collected_images:  # 이미지 소스가 None이 아닌지 확인\n",
    "            collected_images.add(image_src)\n",
    "            if len(collected_images) >= target_image_count:\n",
    "                break\n",
    "    \n",
    "    # 페이지 스크롤 다운\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, image_src in enumerate(collected_images):\n",
    "    try:\n",
    "        if image_src.startswith('data:image'):  # Base64 인코딩된 이미지 처리\n",
    "            header, encoded = image_src.split(',', 1)\n",
    "            data = base64.b64decode(encoded)\n",
    "            file_extension = header.split('/')[1].split(';')[0]  # 파일 확장자 추출 (png, jpeg 등)\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.{file_extension}')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(data)\n",
    "        else:  # 일반 URL 이미지 다운로드\n",
    "            response = requests.get(image_src)\n",
    "            response.raise_for_status()  # 요청에 실패한 경우 예외 발생\n",
    "            filename = os.path.join(folder_name, f'{cafe_name}_image_{idx + 1}.jpg')\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"이미지 다운로드 중 오류 발생: {e}\")\n",
    "\n",
    "print(f\"사진 수집이 완료되었습니다. 총 {len(collected_images)}장의 사진이 '{folder_name}' 폴더에 저장되었습니다.\")\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naver_review_103_턴온_1348444139.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
